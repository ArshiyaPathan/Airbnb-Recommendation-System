{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "reviewer_id    9969\n",
      "listing_id     6983\n",
      "Rating            5\n",
      "dtype: int64\n",
      "RMSE: 1.2113\n",
      "RMSE: 1.2013\n",
      "RMSE: 1.2154\n",
      "RMSE: 1.2194\n",
      "RMSE: 1.1916\n",
      "RMSE: 1.1766\n",
      "RMSE: 1.2000\n",
      "1427\n",
      "After taking full train test\n",
      "Grid Search...\n",
      "best RMSE score\n",
      "1.20061847361\n",
      "combination of parameters that gave the best RMSE score\n",
      "{'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.4}\n",
      "Biased accuracy on A,   RMSE: 0.1010\n",
      "len(predictions)\n",
      "37386974\n",
      "getting top 3 recommendations\n",
      "len(top3_recommendations)\n",
      "6983\n",
      "36894430 [(14369923, 4.2801860113863981), (1185644, 4.2642601679730081), (1073832, 4.2241796871781121)]\n",
      "9765927 [(1881801, 4.2172184632173408), (2134047, 4.1972767775000435), (10423083, 4.1815109399793133)]\n",
      "12936998 [(4501541, 4.2277572183029024), (1737891, 4.218068178636087), (2214323, 4.1993199628622184)]\n",
      "345461 [(12028699, 4.2869922916636485), (13292687, 4.2195689032446637), (8564421, 4.2035988661923973)]\n",
      "6171559 [(2461540, 4.2375517962309734), (19209710, 4.2145062136136886), (14665418, 4.2080897381983409)]\n",
      "3414482 [(728708, 4.1999382576747069), (289665, 4.19978496258042), (15041647, 4.1980966776634316)]\n",
      "14226364 [(1039931, 4.2245680555216927), (14959164, 4.188655127827551), (11888026, 4.1768204529845461)]\n",
      "84143732 [(8456825, 4.223462970185011), (5550458, 4.2047460727397832), (699472, 4.1975816978936402)]\n",
      "65437413 [(13654127, 4.2512869119755488), (17136670, 4.2364004794718886), (115535, 4.2064324594397879)]\n",
      "21168586 [(15319835, 4.2036176654399302), (12292255, 4.2001750991876747), (7967503, 4.1979371374001824)]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from surprise import BaselineOnly\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import KNNBasic,KNNWithMeans\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import PredefinedKFold\n",
    "from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import io\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import csv\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "data_old = pd.read_csv('C:/Users/arshi/Desktop/ArshiyaUSB/Fall2018/256/Project/CMPE256-Airbnb/Module1/generated_rating.csv')\n",
    "\n",
    "#data_old = pd.read_csv('../input/reviews/generated_rating.csv')\n",
    "\n",
    "data_old.head()\n",
    "data_old.nunique()\n",
    "print(\"===========\")\n",
    "df = data_old[['reviewer_id','listing_id','Rating' ]]\n",
    "df.head()\n",
    "print(df.nunique())\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['reviewer_id', 'listing_id', 'Rating']], reader)\n",
    "\n",
    "# define a cross-validation iterator\n",
    "kf = KFold(n_splits=7)\n",
    "algo = SVD(n_factors=500, n_epochs=5, lr_all=0.1)\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    # train and test algorithm.\n",
    "    algo.fit(trainset)\n",
    "    \n",
    "    predictions = algo.test(testset)\n",
    "    \n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "print(len(predictions))\n",
    "\n",
    "# Retrieve the trainset.\n",
    "print(\"After taking full train test\")\n",
    "#trainset = data.build_full_trainset()\n",
    "#testset = trainset.build_anti_testset()\n",
    "raw_ratings = data.raw_ratings\n",
    "\n",
    "# shuffle ratings if you want\n",
    "#random.shuffle(raw_ratings)\n",
    "\n",
    "# A = 90% of the data, B = 10% of the data\n",
    "threshold = int(.7 * len(raw_ratings))\n",
    "A_raw_ratings = raw_ratings[:threshold]\n",
    "B_raw_ratings = raw_ratings[threshold:]\n",
    "\n",
    "data.raw_ratings = A_raw_ratings  # data is now the set A\n",
    "\n",
    "# Select your best algo with grid search.\n",
    "print('Grid Search...')\n",
    "\n",
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse','mae'], cv=3)\n",
    "grid_search.fit(data)\n",
    "print('best RMSE score')\n",
    "print(grid_search.best_score['rmse'])\n",
    "\n",
    "print('combination of parameters that gave the best RMSE score')\n",
    "print(grid_search.best_params['rmse'])\n",
    "algo = grid_search.best_estimator['rmse']\n",
    "\n",
    "# retrain on the whole set A\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Compute biased accuracy on A\n",
    "testset= trainset.build_anti_testset()\n",
    "predictions = algo.test(testset)\n",
    "print('Biased accuracy on A,', end='   ')\n",
    "accuracy.rmse(predictions,verbose=True)\n",
    "print('len(predictions)')\n",
    "print(len(predictions))\n",
    " \n",
    "'''\n",
    "#trainset, testset = train_test_split(data, test_size=0.85)\n",
    "\n",
    "algo.fit(trainset)\n",
    "# Than predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "\n",
    "predictions = algo.test(testset)\n",
    "print(len(predictions))\n",
    "# Compute and print Root Mean Squared Error\n",
    "accuracy.rmse(predictions, verbose=True)   \n",
    "'''\n",
    "def get_top3_recommendations(predictions, topN = 3):\n",
    "     \n",
    "    top_recs = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_recs[uid].append((iid, est))\n",
    "     \n",
    "    for uid, user_ratings in top_recs.items():\n",
    "        user_ratings.sort(key = lambda x: x[1], reverse = True)\n",
    "        top_recs[uid] = user_ratings[:topN]    \n",
    "    return top_recs\n",
    "print('getting top 3 recommendations')\n",
    "\n",
    "top3_recommendations = get_top3_recommendations(predictions,3)\n",
    "\n",
    "print('len(top3_recommendations)')\n",
    "print(len(top3_recommendations))\n",
    "\n",
    "\n",
    "dfo = pd.DataFrame(columns=['UserId', 'Recommended Listing,Rating'])\n",
    "i=0;\n",
    "for uid, user_ratings in top3_recommendations.items():\n",
    "    print(uid, top3_recommendations[uid])\n",
    "    row = [uid, top3_recommendations[uid]]\n",
    "    dfo.loc[i] = row\n",
    "    i=i+1\n",
    "    if(i==10):\n",
    "        break\n",
    "\n",
    "dfo.to_csv('sub.csv', index = False)\n",
    "\n",
    "print(\"done\")     \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
